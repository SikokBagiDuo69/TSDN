{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5056857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from imutils.video import VideoStream\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93595f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################\n",
    "txt_file_path =\"face_detector/deploy.prototxt\"\n",
    "caffemodel_weights_Path = \"face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "Pretrain_face_detection_Model = cv2.dnn.readNet(txt_file_path, caffemodel_weights_Path)\n",
    "\n",
    "# Our trained model for classification of mask and without mask\n",
    "cls_model = load_model(\"MobileNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9effad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes\n",
    "\n",
    "faceProto=\"gad/opencv_face_detector.pbtxt\"\n",
    "faceModel=\"gad/opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"gad/age_deploy.prototxt\"\n",
    "ageModel=\"gad/age_net.caffemodel\"\n",
    "genderProto=\"gad/gender_deploy.prototxt\"\n",
    "genderModel=\"gad/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']\n",
    "\n",
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5664ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func(vid_path=''):\n",
    "    ################\n",
    "        def Realtime_Detection_func(Video_frame, Pretrain_face_detection_Model,cls_model):\n",
    "\n",
    "            (height, width) = Video_frame.shape[:-1]\n",
    "            Img_blob = cv2.dnn.blobFromImage(Video_frame, 1.0, (224, 224),(104.0, 177.0, 123.0))\n",
    "\n",
    "            # pass the blob through the network and obtain the face detections\n",
    "            Pretrain_face_detection_Model.setInput(Img_blob)\n",
    "            face_identify = Pretrain_face_detection_Model.forward()\n",
    "            print(face_identify.shape)\n",
    "\n",
    "            # initialize our list of faces, their corresponding locations,\n",
    "            # and the list of predictions from our face mask network\n",
    "            faces_in_frame_lst = []\n",
    "            faces_location_lst = []\n",
    "            model_preds_lst = []\n",
    "\n",
    "            for i in range(0, face_identify.shape[2]):\n",
    "\n",
    "                conf_value = face_identify[0, 0, i, 2]\n",
    "                if conf_value > 0.6:\n",
    "\n",
    "                    Rectangle_box = face_identify[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                    (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box.astype(\"int\")\n",
    "                    (starting_PointX, starting_PointY) = (max(0, starting_PointX), max(0, starting_PointY))\n",
    "                    (ending_PointX, ending_PointY) = (min(width - 1, ending_PointX), min(height - 1, ending_PointY))\n",
    "                    face_detect = vid_frm[starting_PointY:ending_PointY, starting_PointX:ending_PointX]\n",
    "                    face_RGB = cv2.cvtColor(face_detect, cv2.COLOR_BGR2RGB)\n",
    "                    face_Resize = cv2.resize(face_RGB, (224, 224))\n",
    "                    face_to_array = img_to_array(face_Resize)\n",
    "                    face_rescale = preprocess_input(face_to_array)\n",
    "\n",
    "                    faces_in_frame_lst.append(face_rescale)\n",
    "                    faces_location_lst.append((starting_PointX, starting_PointY, ending_PointX, ending_PointY))\n",
    "                    \n",
    "            if len(faces_in_frame_lst) > 0:\n",
    "\n",
    "                faces_in_frame_lst = np.array(faces_in_frame_lst, dtype=\"float32\")\n",
    "                model_preds_lst = cls_model.predict(faces_in_frame_lst, batch_size=16)\n",
    "\n",
    "            return (model_preds_lst, faces_location_lst)\n",
    "        # loop over the frames from the video stream\n",
    "        if vid_path != '':\n",
    "            print(\"[INFO] starting video stream...\")\n",
    "            vid_stm = VideoStream(src=vid_path).start()\n",
    "            #vid_stm = FileVideoStream(src=vid_path).start()\n",
    "        elif vid_path == '':\n",
    "            print(\"[INFO] starting live stream...\")\n",
    "            vid_stm = VideoStream(src=0).start()\n",
    "        while True:\n",
    "\n",
    "            vid_frm = vid_stm.read()\n",
    "            vid_frm = imutils.resize(vid_frm, width=800)\n",
    "            #=====\n",
    "            \n",
    "            padding=20\n",
    "   \n",
    "            resultImg,faceBoxes=highlightFace(faceNet,vid_frm)\n",
    "            if not faceBoxes:\n",
    "                print(\"No face detected\")\n",
    "\n",
    "            (model_preds_lst, faces_location_lst) = Realtime_Detection_func(vid_frm, Pretrain_face_detection_Model, cls_model)\n",
    "\n",
    "            for (pred,Rectangle_box,faceBox) in zip(model_preds_lst, faces_location_lst,faceBoxes):\n",
    "                (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box\n",
    "                (mask_img, NoMask_img) = pred\n",
    "                \n",
    "                face=vid_frm[max(0,faceBox[1]-padding):\n",
    "                           min(faceBox[3]+padding,vid_frm.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                           :min(faceBox[2]+padding, vid_frm.shape[1]-1)]\n",
    "                blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                genderNet.setInput(blob)\n",
    "                genderPreds=genderNet.forward()\n",
    "                gender=genderList[genderPreds[0].argmax()]\n",
    "                print(f'Gender: {gender}')\n",
    "\n",
    "                ageNet.setInput(blob)\n",
    "                agePreds=ageNet.forward()\n",
    "                age=ageList[agePreds[0].argmax()]\n",
    "                print(f'Age: {age[1:-1]} years')\n",
    "\n",
    "                label = \"Mask\" if mask_img > NoMask_img else \"No Mask\"\n",
    "                color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "                #label = \"{}: {:.2f}%\".format(label, max(mask_img, NoMask_img) * 100)\n",
    "\n",
    "                cv2.putText(vid_frm, label+':'+f'   {gender}, {age}', (starting_PointX, starting_PointY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "                cv2.rectangle(vid_frm, (starting_PointX, starting_PointY), (ending_PointX, ending_PointY), color, 2)\n",
    "\n",
    "            cv2.imshow(\"Video Frame\", vid_frm)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # do a bit of cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        vid_stm.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0948d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit():\n",
    "    #window.destroy()\n",
    "    window.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409eae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Function for opening the\n",
    "    # file explorer window\n",
    "    def browseFiles():\n",
    "        filename = filedialog.askopenfilename(initialdir = \"/\",\n",
    "                                            title = \"Select a File\",\n",
    "                                            filetypes = ((\"Text files\",\n",
    "                                                            \"*.mp4\"),\n",
    "                                                        (\"all files\",\n",
    "                                                            \"*.*\")))\n",
    "        # Change label contents\n",
    "        label_file_explorer.configure(text=\"File Opened: \"+filename)\n",
    "        return(filename)\n",
    "\n",
    "\n",
    "    # Create the root window\n",
    "    window = Tk()\n",
    "\n",
    "    # Set window title\n",
    "    window.title('Face Mask Detection')\n",
    "\n",
    "    # Set window size\n",
    "    window.geometry(\"500x500\")\n",
    "\n",
    "    #Set window background color\n",
    "    window.config(background = \"white\")\n",
    "\n",
    "    # # Create a File Explorer label\n",
    "    label_file_explorer = Label(window,\n",
    "                                text = \"Face mask Detection using Tkinter\",\n",
    "                                width = 100, height = 4,\n",
    "                                fg = \"blue\")\n",
    "\n",
    "    button_explore = Button(window,\n",
    "                            text = \"Browse Files\",\n",
    "                            command = browseFiles)\n",
    "\n",
    "    button_live_stream=Button(window,\n",
    "                        text = \"Live Stream\",\n",
    "                        command = main_func)\n",
    "\n",
    "\n",
    "\n",
    "    button_video_stream=Button(window,\n",
    "                        text = \"Video Stream\",\n",
    "                        command = lambda: main_func(browseFiles()))\n",
    "\n",
    "    button_exit = Button(window,\n",
    "                        text = \"Exit\",\n",
    "                        command = exit)\n",
    "\n",
    "    button_live_stream.grid(column = 1,row = 4)\n",
    "\n",
    "    button_video_stream.grid(column = 1,row = 5)\n",
    "\n",
    "    button_exit.grid(column = 1,row = 6)\n",
    "    # Let the window wait for any events\n",
    "    window.mainloop()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c7db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 1s 691ms/step\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Gender: Male\n",
      "Age: 4-6 years\n",
      "No face detected\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Gender: Male\n",
      "Age: 8-12 years\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Gender: Male\n",
      "Age: 4-6 years\n",
      "(1, 1, 200, 7)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Gender: Male\n",
      "Age: 25-32 years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/noumanahmad/miniforge3/envs/new_env/lib/python3.8/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-6-194ed2837098>\", line 46, in <lambda>\n",
      "    command = lambda: main_func(browseFiles()))\n",
      "  File \"<ipython-input-4-2a323cdda230>\", line 54, in main_func\n",
      "    vid_frm = imutils.resize(vid_frm, width=800)\n",
      "  File \"/Users/noumanahmad/miniforge3/envs/new_env/lib/python3.8/site-packages/imutils/convenience.py\", line 69, in resize\n",
      "    (h, w) = image.shape[:2]\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990b702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
